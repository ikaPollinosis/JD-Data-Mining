{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ.update({'MALLET_HOME':r'C:\\Users\\28772\\PycharmProjects\\analysis\\mallet-2.0.8'})\n",
    "mallet_path = 'C:/Users/28772/PycharmProjects/analysis/mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "# 导入数据\n",
    "df = pd.read_csv('adjusted_RandomForestClassifier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\28772\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.967 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "zh_pattern = re.compile(u'[\\u4e00-\\u9fa5]+')\n",
    "stop_word = [line.strip() for line in open ('chineseStopWords.txt','r').readlines()]\n",
    "def extract_words(word):\n",
    "    word = str(word).strip()\n",
    "    zh_word = re.findall(zh_pattern,word)\n",
    "    lst = jieba.cut(''.join(zh_word))\n",
    "    final_word = [char for char in lst if char not in stop_word]\n",
    "    return ' '.join(final_word) #空格隔开\n",
    "data_e = df['message'].apply(lambda x:extract_words(x))   #对整列进行操作\n",
    "data_extract = pd.DataFrame(data_e.values,columns=['content'])  #转换成列表"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 content  predict  \\\n0                                            鼠标垫 抠门 扣到 家        1   \n1                                     刚买 两天 降价 多买个 鼠标 保价        1   \n2                                            电脑 刚买 系统 更新        1   \n3                                            不到 十天 降价 厉害        1   \n4                                           刚买 完 降 两百块 钱        1   \n...                                                  ...      ...   \n54995  第一次 买 华为 电脑 开机 流畅 第一次 设置 友好 不用 想太多 跟着 默认设置 很快 ...        0   \n54996                                  电脑 运行 速度 很快 外形 好看        0   \n54997                          笔记本 外观 很漂亮 拿到 手里 分量 做工 精细        0   \n54998                                      外观 不错 键盘 手感 好        0   \n54999                                  本子 收到 物流 超快 宝贝 不错        0   \n\n       0 probability  \n0           0.128603  \n1           0.000000  \n2           0.021998  \n3           0.007320  \n4           0.029705  \n...              ...  \n54995       1.000000  \n54996       1.000000  \n54997       1.000000  \n54998       0.920000  \n54999       1.000000  \n\n[55000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>predict</th>\n      <th>0 probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>鼠标垫 抠门 扣到 家</td>\n      <td>1</td>\n      <td>0.128603</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>刚买 两天 降价 多买个 鼠标 保价</td>\n      <td>1</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>电脑 刚买 系统 更新</td>\n      <td>1</td>\n      <td>0.021998</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>不到 十天 降价 厉害</td>\n      <td>1</td>\n      <td>0.007320</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>刚买 完 降 两百块 钱</td>\n      <td>1</td>\n      <td>0.029705</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>54995</th>\n      <td>第一次 买 华为 电脑 开机 流畅 第一次 设置 友好 不用 想太多 跟着 默认设置 很快 ...</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>54996</th>\n      <td>电脑 运行 速度 很快 外形 好看</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>54997</th>\n      <td>笔记本 外观 很漂亮 拿到 手里 分量 做工 精细</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>54998</th>\n      <td>外观 不错 键盘 手感 好</td>\n      <td>0</td>\n      <td>0.920000</td>\n    </tr>\n    <tr>\n      <th>54999</th>\n      <td>本子 收到 物流 超快 宝贝 不错</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>55000 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_extract['predict'] = df['predict']\n",
    "data_extract['0 probability'] = df['0 probability']\n",
    "data_extract"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 content  predict  \\\n367    换货 三次 发 别人 用过 电脑 忽悠 消费者 通电 次数 通电 时间 主机 写入 量 别人...        0   \n847                                     产品 不错 可惜 价格 跌 厉害        0   \n2284   运行 速度 屏幕 效果 散热 性能 好 外形 外观 轻薄 程度 挺重 运行 速度 屏幕 效果...        0   \n2549                              零颗 星 同价位 电脑 相比 推荐 买 品牌        0   \n2647                                    产品 不错 可惜 价格 跌 厉害        0   \n...                                                  ...      ...   \n54995  第一次 买 华为 电脑 开机 流畅 第一次 设置 友好 不用 想太多 跟着 默认设置 很快 ...        0   \n54996                                  电脑 运行 速度 很快 外形 好看        0   \n54997                          笔记本 外观 很漂亮 拿到 手里 分量 做工 精细        0   \n54998                                      外观 不错 键盘 手感 好        0   \n54999                                  本子 收到 物流 超快 宝贝 不错        0   \n\n       0 probability  \n367         0.678140  \n847         0.504140  \n2284        0.747649  \n2549        0.504505  \n2647        0.504140  \n...              ...  \n54995       1.000000  \n54996       1.000000  \n54997       1.000000  \n54998       0.920000  \n54999       1.000000  \n\n[49845 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>predict</th>\n      <th>0 probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>367</th>\n      <td>换货 三次 发 别人 用过 电脑 忽悠 消费者 通电 次数 通电 时间 主机 写入 量 别人...</td>\n      <td>0</td>\n      <td>0.678140</td>\n    </tr>\n    <tr>\n      <th>847</th>\n      <td>产品 不错 可惜 价格 跌 厉害</td>\n      <td>0</td>\n      <td>0.504140</td>\n    </tr>\n    <tr>\n      <th>2284</th>\n      <td>运行 速度 屏幕 效果 散热 性能 好 外形 外观 轻薄 程度 挺重 运行 速度 屏幕 效果...</td>\n      <td>0</td>\n      <td>0.747649</td>\n    </tr>\n    <tr>\n      <th>2549</th>\n      <td>零颗 星 同价位 电脑 相比 推荐 买 品牌</td>\n      <td>0</td>\n      <td>0.504505</td>\n    </tr>\n    <tr>\n      <th>2647</th>\n      <td>产品 不错 可惜 价格 跌 厉害</td>\n      <td>0</td>\n      <td>0.504140</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>54995</th>\n      <td>第一次 买 华为 电脑 开机 流畅 第一次 设置 友好 不用 想太多 跟着 默认设置 很快 ...</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>54996</th>\n      <td>电脑 运行 速度 很快 外形 好看</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>54997</th>\n      <td>笔记本 外观 很漂亮 拿到 手里 分量 做工 精细</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>54998</th>\n      <td>外观 不错 键盘 手感 好</td>\n      <td>0</td>\n      <td>0.920000</td>\n    </tr>\n    <tr>\n      <th>54999</th>\n      <td>本子 收到 物流 超快 宝贝 不错</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>49845 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = data_extract[(data_extract['predict'] == 1)]\n",
    "df0 = data_extract[(data_extract['predict'] == 0)]\n",
    "df0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[['鼠标垫', '抠门', '扣到', '家']]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts1 = []\n",
    "for i in df1['content']:\n",
    "    cts1.append(i.split(' '))\n",
    "cts1[:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[['换货',\n  '三次',\n  '发',\n  '别人',\n  '用过',\n  '电脑',\n  '忽悠',\n  '消费者',\n  '通电',\n  '次数',\n  '通电',\n  '时间',\n  '主机',\n  '写入',\n  '量',\n  '别人',\n  '痕迹',\n  '屏幕',\n  '坏点',\n  '屏幕',\n  '别人',\n  '没',\n  '擦',\n  '干净',\n  '指纹',\n  '印有',\n  '图有',\n  '证据',\n  '希望',\n  '开箱',\n  '验机',\n  '仔细',\n  '一点',\n  '别买',\n  '别人',\n  '二手',\n  '笔记本电脑',\n  '二手',\n  '名不虚传']]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts0 = []\n",
    "for i in df0['content']:\n",
    "    cts0.append(i.split(' '))\n",
    "cts0[:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "id2word1 = corpora.Dictionary(cts1)\n",
    "id2word1.save_as_text(\"dictionary\")\n",
    "texts1 = cts1\n",
    "corpus1 = [id2word1.doc2bow(text) for text in texts1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('家', 1), ('扣到', 1), ('抠门', 1), ('鼠标垫', 1)]]\n"
     ]
    }
   ],
   "source": [
    "print([[(id2word1[id],freq)for id, freq in cp]for cp in corpus1[:1]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "id2word0 = corpora.Dictionary(cts0)\n",
    "id2word0.save_as_text(\"dictionary\")\n",
    "texts0 = cts0\n",
    "corpus0 = [id2word0.doc2bow(text) for text in texts0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('一点', 1), ('三次', 1), ('主机', 1), ('二手', 2), ('仔细', 1), ('写入', 1), ('别买', 1), ('别人', 4), ('印有', 1), ('发', 1), ('名不虚传', 1), ('图有', 1), ('坏点', 1), ('屏幕', 2), ('希望', 1), ('干净', 1), ('开箱', 1), ('忽悠', 1), ('指纹', 1), ('换货', 1), ('擦', 1), ('时间', 1), ('次数', 1), ('没', 1), ('消费者', 1), ('用过', 1), ('电脑', 1), ('痕迹', 1), ('笔记本电脑', 1), ('证据', 1), ('通电', 2), ('量', 1), ('验机', 1)]]\n"
     ]
    }
   ],
   "source": [
    "print([[(id2word0[id],freq)for id, freq in cp]for cp in corpus0[:1]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 一致性检验仅作为参考（修改）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path,corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "model_list, coherence_values = compute_coherence_values(\n",
    "    dictionary=id2word1, corpus=corpus1, texts=cts1, start=2, limit=10, step=2)\n",
    "# Show graph\n",
    "limit=10; start=2; step=2;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path,corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "model_list, coherence_values = compute_coherence_values(\n",
    "    dictionary=id2word0, corpus=corpus0, texts=cts0, start=2, limit=10, step=2)\n",
    "# Show graph\n",
    "limit=10; start=2; step=2;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 最佳LDA模型\n",
    "optimal_model0 = gensim.models.wrappers.LdaMallet(mallet_path,corpus=corpus0, num_topics=6, id2word=id2word0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "optimal_model1 = gensim.models.wrappers.LdaMallet(mallet_path,corpus=corpus1, num_topics=6, id2word=id2word1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 可显示10个以上的话题关键词，并手动筛选（修改）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_topics0 = optimal_model0.show_topics(formatted=False,num_words=20)\n",
    "model_topics0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_topics1 = optimal_model1.show_topics(formatted=False,num_words=20)\n",
    "model_topics1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 为评价打主题标签\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x:(x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords0 = format_topics_sentences(ldamodel=optimal_model0, corpus=corpus0, texts=texts0)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic0 = df_topic_sents_keywords0.reset_index()\n",
    "df_dominant_topic0.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28772\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\28772\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Show\n",
    "df_dominant_topic0.head(10)\n",
    "df0['LDA_Topic'] = df_dominant_topic0['Dominant_Topic']\n",
    "df0['LDA_Keywords'] = df_dominant_topic0['Keywords']\n",
    "df0.to_csv('LDAResult_pos.csv',index=0,columns=None,encoding='utf_8')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 为评价打主题标签\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x:(x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords1 = format_topics_sentences(ldamodel=optimal_model1, corpus=corpus1, texts=texts1)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic1 = df_topic_sents_keywords1.reset_index()\n",
    "df_dominant_topic1.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28772\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\28772\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Show\n",
    "df_dominant_topic1.head(10)\n",
    "df1['LDA_Topic'] = df_dominant_topic1['Dominant_Topic']\n",
    "df1['LDA_Keywords'] = df_dominant_topic1['Keywords']\n",
    "df1.to_csv('LDAResult_neg.csv',index=0,columns=None,encoding='utf_8')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
